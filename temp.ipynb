{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# _features = {\"hotel_star_rating\": (0, 5),\n",
    "#              \"no_of_adults\": (1, 19),\n",
    "#              \"no_of_children\": (0, 8),\n",
    "#              \"no_of_extra_bed\": (0, 4),\n",
    "#              \"no_of_room\": (1, 9),\n",
    "#              \"waterfront\": (0, 1),\n",
    "#              \"view\": (0, 4),\n",
    "#              \"condition\": (1, 5),\n",
    "#              \"grade\": (1, 13),\n",
    "#              \"sqft_above\": (250, 10000),\n",
    "#              _sqft_basement_label: (0, 5000),\n",
    "#              \"yr_built\": (1900, 2015),\n",
    "#              _yr_renovated_label: (0, 2015),\n",
    "#              \"zipcode\": (98000, 99000),\n",
    "#              \"lat\": (47, 48),\n",
    "#              \"long\": (-123, -121)}\n",
    "\n",
    "_dates = [\"booking_datetime\", \"checkin_date\", \"checkout_date\", \"hotel_live_date\", \"cancellation_datetime\"]\n",
    "_irrelevant_features = [\"h_booking_id\", \"hotel_chain_code\", \"hotel_brand_code\", \"request_earlycheckin\",\n",
    "                        \"request_airport\", \"request_twinbeds\", \"request_largebed\", \"request_highfloor\",\n",
    "                        \"request_latecheckin\", \"request_nonesmoke\"]\n",
    "_categorial_features = [\"hotel_country_code\", \"accommadation_type_name\", \"charge_option\",\n",
    "                        \"customer_nationality\", \"guest_nationality_country_name\", \"origin_country_code\",\n",
    "                        \"original_payment_method\", \"original_payment_type\", \"original_payment_currency\",\n",
    "                        \"hotel_area_code\", \"is_first_booking\", \"is_user_logged_in\"]  #\"cancellation_policy_code\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def split_data(X: pd.DataFrame):\n",
    "    # Splitting the DataFrame into three parts: train, validation, and test\n",
    "    train_df, temp_df = train_test_split(X, test_size=0.4, random_state=42)\n",
    "    validation_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Printing the sizes of the resulting DataFrames\n",
    "    print(\"Train set size:\", len(train_df))\n",
    "    print(\"Validation set size:\", len(validation_df))\n",
    "    print(\"Test set size:\", len(test_df))\n",
    "    return train_df, test_df, validation_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _fill_missings_values(X: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    fills missings values by prediction Parameters\n",
    "    ----------\n",
    "    X : DataFrame of shape (n_samples, n_features)\n",
    "        Design matrix of regression problem\n",
    "    \"\"\"\n",
    "\n",
    "    model = LinearRegression(include_intercept=True)\n",
    "    for label in X.columns:\n",
    "        label_X = X.dropna(subset=X.columns.difference([label]))\n",
    "        data_to_pred = label_X[label_X[label].isnull()]\n",
    "        if data_to_pred.empty:\n",
    "            continue\n",
    "\n",
    "        X_not_null = label_X[label_X[label].notna()]\n",
    "        y_pred_train = X_not_null[label]\n",
    "        X_pred_train = X_not_null.drop(label, axis=1)\n",
    "        X_pred_test = data_to_pred.drop(label, axis=1)\n",
    "        model.fit(X_pred_train, y_pred_train)\n",
    "\n",
    "        predicted_vals = model.predict(X_pred_test).round(decimals=2)\n",
    "        X[label].update(pd.Series(predicted_vals, index=X_pred_test.index))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def load_data(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load city daily temperature dataset and preprocess data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: str\n",
    "        Path to house prices dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Design matrix and response vector (Temp)\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename, parse_dates=_dates)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def add_extra_features(X: pd.DataFrame):\n",
    "    X['order_canceled'] = np.where(df['cancellation_datetime'] != np.nan, 1, 0)\n",
    "    X['duration_days'] = (X['checkin_date'] - X['checkout_date']).dt.days\n",
    "    X['booked_days_before'] = (X['booking_datetime'] - X['checkin_date']).dt.days\n",
    "    X['cencel_code_day_one'] = df.apply(lambda row: parse_code_day_one(row['cancellation_policy_code']), axis=1)\n",
    "    X['cencel_code_return_one'] = df.apply(lambda row: parse_code_return_one(row['cancellation_policy_code']), axis=1)\n",
    "    X['cencel_code_day_two'] = df.apply(lambda row: parse_code_day_two(row['cancellation_policy_code']), axis=1)\n",
    "    X['cencel_code_return_two'] = df.apply(lambda row: parse_code_return_two(row['cancellation_policy_code']), axis=1)\n",
    "    X['parse_code_no_show'] = df.apply(lambda row: parse_code_no_show(row['cancellation_policy_code']), axis=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def preprocess_remove_columns_add_dummy(X: pd.DataFrame):\n",
    "    for feat in _irrelevant_features:\n",
    "        X.drop(feat, axis=1, inplace=True)\n",
    "        print(X[feat])\n",
    "    X = pd.get_dummies(df, prefix=_categorial_features, columns=_categorial_features)\n",
    "    return X\n",
    "\n",
    "\n",
    "def parse_code_day_one(row):\n",
    "    numeric_values = re.findall(r'\\d+', row)\n",
    "    alphabetic_substrings = re.findall(r'[a-zA-Z]+', row)\n",
    "    try:\n",
    "        if alphabetic_substrings[0] == 'D':\n",
    "            return float(numeric_values[0])\n",
    "    except:\n",
    "        return 0\n",
    "    return 0\n",
    "\n",
    "\n",
    "def parse_code_return_one(row):\n",
    "    numeric_values = re.findall(r'\\d+', row)\n",
    "    alphabetic_substrings = re.findall(r'[a-zA-Z]+', row)\n",
    "    try:\n",
    "        if alphabetic_substrings[1] == 'P':\n",
    "            return float(numeric_values[1]) / 100\n",
    "        elif alphabetic_substrings[1] == 'N':\n",
    "            return -1 * float(numeric_values[1])\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def parse_code_day_two(row):\n",
    "    numeric_values = re.findall(r'\\d+', row)\n",
    "    alphabetic_substrings = re.findall(r'[a-zA-Z]+', row)\n",
    "    try:\n",
    "        if alphabetic_substrings[2] == 'D':\n",
    "            return float(numeric_values[2])\n",
    "    except:\n",
    "        return 0\n",
    "    return 0\n",
    "\n",
    "\n",
    "def parse_code_return_two(row):\n",
    "    numeric_values = re.findall(r'\\d+', row)\n",
    "    alphabetic_substrings = re.findall(r'[a-zA-Z]+', row)\n",
    "    try:\n",
    "        if alphabetic_substrings[3] == 'P':\n",
    "            return float(numeric_values[1]) / 100\n",
    "        elif alphabetic_substrings[3] == 'N':\n",
    "            return -1 * float(numeric_values[1])\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def parse_code_no_show(row):\n",
    "    numeric_values = re.findall(r'\\d+', row)\n",
    "    alphabetic_substrings = re.findall(r'[a-zA-Z]+', row)\n",
    "    try:\n",
    "        if len(alphabetic_substrings) % 2 != 0:\n",
    "            if alphabetic_substrings[-1] == 'P':\n",
    "                return float(numeric_values[-1]) / 100\n",
    "            if alphabetic_substrings[-1] == 'N':\n",
    "                return -1 * float(numeric_values[1])\n",
    "        return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def proccess_dates(df: pd.DataFrame):\n",
    "    for label in _dates:\n",
    "        df[f\"{label}_dayofyear\"] = df[label].dt.dayofyear\n",
    "        df[f\"{label}_year\"] = df[label].dt.year"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_data(X: pd.DataFrame, y: typing.Optional[pd.Series] = None):\n",
    "    \"\"\"\n",
    "    preprocess data\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : DataFrame of shape (n_samples, n_features)\n",
    "        Design matrix of regression problem\n",
    "\n",
    "    y : array-like of shape (n_samples, )\n",
    "        Response vector corresponding given samples\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Post-processed design matrix and response vector (prices) - either as a single\n",
    "    DataFrame or a Tuple[DataFrame, Series]\n",
    "    \"\"\"\n",
    "\n",
    "    is_train = y is not None\n",
    "    if is_train:\n",
    "        X = X.assign(order_canceled=y)\n",
    "        X = X.drop_duplicates()\n",
    "\n",
    "\n",
    "    X = X.drop(_irrelevant_features, axis=1)  # Irrelevant features\n",
    "\n",
    "    proccess_dates(X)\n",
    "    X = X.drop(_dates, axis=1)  # Irrelevant features\n",
    "\n",
    "    for label in X:  # Replaces invalid values with temporary nan value\n",
    "        X[label] = X[label].mask(~X[label].between(X[label][0], X[label][1], inclusive=\"both\"), np.nan)\n",
    "\n",
    "    for category in _categorial_features:  # Handles categorial features\n",
    "        X[category] = X[category].astype('category')\n",
    "        X = pd.get_dummies(X, prefix=category, columns=[category])\n",
    "\n",
    "    add_extra_features(X)\n",
    "\n",
    "    _fill_missings_values(X)\n",
    "    if not is_train:\n",
    "        return X\n",
    "\n",
    "    X = X.reset_index(drop=True)\n",
    "    post_processed_y = X[\"y_train\"]\n",
    "    return X.drop(\"y_train\", axis=1), post_processed_y\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "#read data\n",
    "# Specify the file path\n",
    "file_path = './data_files/agoda_cancellation_train.csv'\n",
    "# Read the CSV file into a DataFrame\n",
    "df = load_data(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          h_booking_id    booking_datetime checkin_date checkout_date  \\\n",
      "0 -9223194055642672935 2018-06-28 21:15:00   2018-07-09    2018-07-13   \n",
      "1 -9222713784330706132 2018-08-10 22:31:00   2018-08-16    2018-08-17   \n",
      "2 -9222411208325704942 2018-09-14 07:55:00   2018-09-14    2018-09-15   \n",
      "3 -9222220845872895471 2018-06-25 07:33:00   2018-07-02    2018-07-03   \n",
      "4 -9221127186162682116 2018-07-23 10:06:00   2018-08-09    2018-08-10   \n",
      "\n",
      "   hotel_id hotel_country_code     hotel_live_date  hotel_star_rating  \\\n",
      "0      6452                 HK 2009-06-28 02:02:00                4.0   \n",
      "1     47729                 CN 2011-06-07 11:52:00                4.0   \n",
      "2    780431                 KR 2014-11-20 15:43:00                4.0   \n",
      "3    291365                 JP 2011-11-21 12:27:00                3.0   \n",
      "4    479046                 TH 2013-06-06 10:04:00                3.0   \n",
      "\n",
      "  accommadation_type_name charge_option  ...  request_highfloor  \\\n",
      "0                   Hotel       Pay Now  ...                NaN   \n",
      "1                   Hotel     Pay Later  ...                0.0   \n",
      "2                   Hotel       Pay Now  ...                0.0   \n",
      "3                   Hotel     Pay Later  ...                0.0   \n",
      "4                  Resort     Pay Later  ...                0.0   \n",
      "\n",
      "  request_largebed  request_twinbeds request_airport  request_earlycheckin  \\\n",
      "0              NaN               NaN             NaN                   NaN   \n",
      "1              0.0               1.0             0.0                   0.0   \n",
      "2              0.0               0.0             0.0                   0.0   \n",
      "3              1.0               0.0             0.0                   0.0   \n",
      "4              1.0               0.0             0.0                   0.0   \n",
      "\n",
      "   cancellation_datetime  hotel_area_code  hotel_brand_code hotel_chain_code  \\\n",
      "0                    NaT             1192               NaN              NaN   \n",
      "1                    NaT             5617             902.0            600.0   \n",
      "2                    NaT             3819               NaN              NaN   \n",
      "3                    NaT             2379             466.0            236.0   \n",
      "4             2018-07-23             1506               NaN              NaN   \n",
      "\n",
      "  hotel_city_code  \n",
      "0             142  \n",
      "1            1273  \n",
      "2            2799  \n",
      "3            1448  \n",
      "4             616  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "<bound method DataFrame.info of               h_booking_id    booking_datetime checkin_date checkout_date  \\\n",
      "0     -9223194055642672935 2018-06-28 21:15:00   2018-07-09    2018-07-13   \n",
      "1     -9222713784330706132 2018-08-10 22:31:00   2018-08-16    2018-08-17   \n",
      "2     -9222411208325704942 2018-09-14 07:55:00   2018-09-14    2018-09-15   \n",
      "3     -9222220845872895471 2018-06-25 07:33:00   2018-07-02    2018-07-03   \n",
      "4     -9221127186162682116 2018-07-23 10:06:00   2018-08-09    2018-08-10   \n",
      "...                    ...                 ...          ...           ...   \n",
      "58654  9221958224902563533 2018-07-18 22:07:00   2018-08-04    2018-08-05   \n",
      "58655  9222015611933681753 2018-09-05 12:07:00   2018-09-06    2018-09-08   \n",
      "58656  9222651806661094957 2018-06-08 23:23:00   2018-08-09    2018-08-11   \n",
      "58657  9223221736086584899 2018-09-02 08:18:00   2018-09-10    2018-09-12   \n",
      "58658  9223338323510018406 2018-07-07 10:46:00   2018-07-12    2018-07-14   \n",
      "\n",
      "       hotel_id hotel_country_code     hotel_live_date  hotel_star_rating  \\\n",
      "0          6452                 HK 2009-06-28 02:02:00                4.0   \n",
      "1         47729                 CN 2011-06-07 11:52:00                4.0   \n",
      "2        780431                 KR 2014-11-20 15:43:00                4.0   \n",
      "3        291365                 JP 2011-11-21 12:27:00                3.0   \n",
      "4        479046                 TH 2013-06-06 10:04:00                3.0   \n",
      "...         ...                ...                 ...                ...   \n",
      "58654   2975682                 ID 2017-10-12 11:01:00                2.0   \n",
      "58655   3579174                 PH 2017-11-30 00:42:00                4.0   \n",
      "58656    407156                 TH 2015-03-14 05:18:00                5.0   \n",
      "58657    303186                 DE 2012-04-13 17:48:00                0.0   \n",
      "58658   2227632                 HK 2017-06-19 10:06:00                4.0   \n",
      "\n",
      "             accommadation_type_name charge_option  ...  request_highfloor  \\\n",
      "0                              Hotel       Pay Now  ...                NaN   \n",
      "1                              Hotel     Pay Later  ...                0.0   \n",
      "2                              Hotel       Pay Now  ...                0.0   \n",
      "3                              Hotel     Pay Later  ...                0.0   \n",
      "4                             Resort     Pay Later  ...                0.0   \n",
      "...                              ...           ...  ...                ...   \n",
      "58654  Guest House / Bed & Breakfast       Pay Now  ...                0.0   \n",
      "58655                      Apartment       Pay Now  ...                0.0   \n",
      "58656                          Hotel       Pay Now  ...                NaN   \n",
      "58657                         Hostel       Pay Now  ...                0.0   \n",
      "58658                          Hotel       Pay Now  ...                NaN   \n",
      "\n",
      "      request_largebed  request_twinbeds request_airport  \\\n",
      "0                  NaN               NaN             NaN   \n",
      "1                  0.0               1.0             0.0   \n",
      "2                  0.0               0.0             0.0   \n",
      "3                  1.0               0.0             0.0   \n",
      "4                  1.0               0.0             0.0   \n",
      "...                ...               ...             ...   \n",
      "58654              1.0               0.0             0.0   \n",
      "58655              0.0               0.0             0.0   \n",
      "58656              NaN               NaN             NaN   \n",
      "58657              0.0               1.0             0.0   \n",
      "58658              NaN               NaN             NaN   \n",
      "\n",
      "       request_earlycheckin  cancellation_datetime  hotel_area_code  \\\n",
      "0                       NaN                    NaT             1192   \n",
      "1                       0.0                    NaT             5617   \n",
      "2                       0.0                    NaT             3819   \n",
      "3                       0.0                    NaT             2379   \n",
      "4                       0.0             2018-07-23             1506   \n",
      "...                     ...                    ...              ...   \n",
      "58654                   0.0             2018-07-22              995   \n",
      "58655                   0.0                    NaT              674   \n",
      "58656                   NaN                    NaT             3823   \n",
      "58657                   0.0                    NaT             4663   \n",
      "58658                   NaN                    NaT             3023   \n",
      "\n",
      "       hotel_brand_code hotel_chain_code hotel_city_code  \n",
      "0                   NaN              NaN             142  \n",
      "1                 902.0            600.0            1273  \n",
      "2                   NaN              NaN            2799  \n",
      "3                 466.0            236.0            1448  \n",
      "4                   NaN              NaN             616  \n",
      "...                 ...              ...             ...  \n",
      "58654               NaN              NaN            2066  \n",
      "58655               NaN              NaN            2310  \n",
      "58656             754.0             55.0            2477  \n",
      "58657               NaN              NaN            1935  \n",
      "58658             477.0            638.0             142  \n",
      "\n",
      "[58659 rows x 39 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Print the DataFrame\n",
    "print(df.head())\n",
    "print(df.info)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['hotel_country_code', 'accommadation_type_name', 'charge_option',\\n       'customer_nationality', 'guest_nationality_country_name',\\n       'origin_country_code', 'original_payment_method',\\n       'original_payment_type', 'original_payment_currency', 'hotel_area_code',\\n       'is_first_booking', 'is_user_logged_in'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/g4/gm4pqnsj5rv4yy7vyw0s95700000gn/T/ipykernel_88406/348235248.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0madd_extra_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpreprocess_remove_columns_add_dummy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnunique\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#add columns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# print(df['order_canceled'].head(100))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/g4/gm4pqnsj5rv4yy7vyw0s95700000gn/T/ipykernel_88406/2710255217.py\u001B[0m in \u001B[0;36mpreprocess_remove_columns_add_dummy\u001B[0;34m(X)\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mfeat\u001B[0m \u001B[0;32min\u001B[0m \u001B[0m_irrelevant_features\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_dummies\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprefix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0m_categorial_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0m_categorial_features\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/iml.env/lib/python3.7/site-packages/pandas/core/reshape/reshape.py\u001B[0m in \u001B[0;36mget_dummies\u001B[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001B[0m\n\u001B[1;32m    888\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Input must be a list-like for parameter `columns`\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    889\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 890\u001B[0;31m             \u001B[0mdata_to_encode\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    891\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    892\u001B[0m         \u001B[0;31m# validate prefixes and separator to avoid silently dropping cols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/iml.env/lib/python3.7/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3462\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_iterator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3463\u001B[0m                 \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3464\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_listlike_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3465\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3466\u001B[0m         \u001B[0;31m# take() does not accept boolean indexers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/iml.env/lib/python3.7/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m_get_listlike_indexer\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1312\u001B[0m             \u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_indexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reindex_non_unique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1313\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1314\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_read_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1315\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1316\u001B[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001B[0;32m~/opt/anaconda3/envs/iml.env/lib/python3.7/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m_validate_read_indexer\u001B[0;34m(self, key, indexer, axis)\u001B[0m\n\u001B[1;32m   1372\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0muse_interval_msg\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1373\u001B[0m                     \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1374\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1375\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1376\u001B[0m             \u001B[0mnot_found\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mensure_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmissing_mask\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnonzero\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of [Index(['hotel_country_code', 'accommadation_type_name', 'charge_option',\\n       'customer_nationality', 'guest_nationality_country_name',\\n       'origin_country_code', 'original_payment_method',\\n       'original_payment_type', 'original_payment_currency', 'hotel_area_code',\\n       'is_first_booking', 'is_user_logged_in'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "add_extra_features(df)\n",
    "df = preprocess_remove_columns_add_dummy(df)\n",
    "df.nunique\n",
    "#add columns\n",
    "# print(df['order_canceled'].head(100))\n",
    "# print(df['cencel_code_day_two'].head(100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 35195\n",
      "Validation set size: 11732\n",
      "Test set size: 11732\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/g4/gm4pqnsj5rv4yy7vyw0s95700000gn/T/ipykernel_88406/1294938242.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mClassification\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mClassification\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mtrain_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalidation_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msplit_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mClassification\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_all\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_df\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtrain_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'order_canceled'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtest_df\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtest_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'order_canceled'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/iml_hackathon/Classification.py\u001B[0m in \u001B[0;36mrun_all\u001B[0;34m(self, X_train, y_train, X_test, y_test)\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    219\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mrun_all\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 220\u001B[0;31m         \u001B[0mX_train_std\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test_std\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_train_mm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test_mm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata_scaling\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    221\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    222\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"logistic_regression:\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/iml_hackathon/Classification.py\u001B[0m in \u001B[0;36mdata_scaling\u001B[0;34m(self, X_train, X_test)\u001B[0m\n\u001B[1;32m    207\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdata_scaling\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    208\u001B[0m         \u001B[0mstd_scaler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mStandardScaler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 209\u001B[0;31m         \u001B[0mstd_scaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    210\u001B[0m         \u001B[0mX_train_std\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstd_scaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m         \u001B[0mX_test_std\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstd_scaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/iml.env/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    804\u001B[0m         \u001B[0;31m# Reset internal state before fitting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    805\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 806\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpartial_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    807\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    808\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpartial_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/iml.env/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001B[0m in \u001B[0;36mpartial_fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    845\u001B[0m             \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mFLOAT_DTYPES\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    846\u001B[0m             \u001B[0mforce_all_finite\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"allow-nan\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 847\u001B[0;31m             \u001B[0mreset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfirst_call\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    848\u001B[0m         )\n\u001B[1;32m    849\u001B[0m         \u001B[0mn_features\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/iml.env/lib/python3.7/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    564\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Validation should be done on X, y or both.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    565\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 566\u001B[0;31m             \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    567\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    568\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/iml.env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    744\u001B[0m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcasting\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"unsafe\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    745\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 746\u001B[0;31m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    747\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    748\u001B[0m                 raise ValueError(\n",
      "\u001B[0;32m~/opt/anaconda3/envs/iml.env/lib/python3.7/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m   1991\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1992\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mNpDtype\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1993\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1994\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1995\u001B[0m     def __array_wrap__(\n",
      "\u001B[0;31mTypeError\u001B[0m: float() argument must be a string or a number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "from Classification import Classification\n",
    "\n",
    "train_df, test_df, validation_df = split_data(df)\n",
    "Classification().run_all(train_df, train_df['order_canceled'], test_df, test_df['order_canceled'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-iml.env-py",
   "language": "python",
   "display_name": "Python [conda env:iml.env] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}